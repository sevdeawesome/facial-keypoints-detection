{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cea7897-6033-4325-a80d-21351e42ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.notebook_2_utils import * \n",
    "import utils.notebook_2_utils as utils\n",
    "\n",
    "training_df = pd.read_csv(\"data/training.csv\")\n",
    "lookup_df = pd.read_csv(\"data/IdLookupTable.csv\")\n",
    "training_df.fillna(method = 'ffill',inplace = True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57d834ad-913c-4234-8f99-c1f324f1c188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3f050b1-6529-409a-9183-1845badd99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, val_X, val_Y = create_train_test_sets_nchw(training_df, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7629da-e48d-40d3-95eb-718337d2c576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "937f7471-73e5-4282-a03d-7330fa1f7ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5640, 1, 96, 96]),\n",
       " torch.Size([5640, 30]),\n",
       " torch.Size([1409, 1, 96, 96]),\n",
       " torch.Size([1409, 30]),\n",
       " tensor(1.),\n",
       " tensor(0.9993),\n",
       " tensor(0.9941))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_Y.shape, val_X.shape, val_Y.shape, train_X.max(), train_Y.max(), val_Y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aeef4d-1574-4717-995a-a004159741d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e997724-0722-48c5-a13a-607178603462",
   "metadata": {},
   "source": [
    "## Very Simple CNN Model\n",
    "* Input shape:  64, 1, 96, 96 (nchw)\n",
    "* Output shape: 64, 30 (nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ebfb08-d143-42bc-ba71-5c1383f60e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d371b-b988-4055-bdc4-86c844901904",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30eacd5f-388f-43e0-98ac-d47402292239",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_dim: int, output_dim: int):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=input_shape, out_channels=hidden_dim, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = nn.Conv2d(in_channels=hidden_dim, out_channels=hidden_dim, kernel_size=3, stride=1, padding=1)\n",
    "        self.fc1 = nn.Linear(hidden_dim * 24 * 24, hidden_dim) #this is multiplied by 7*7 because the image is 28*28 and we have 2 conv layers with stride 1 and padding 1\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, kernel_size=2, stride=2)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492ce700-b41f-4c44-a5a7-b55916731ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7ff48-ed7a-4ad3-8340-1d518917bdd4",
   "metadata": {},
   "source": [
    "## Control Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bed53bd1-43f8-4d82-9d9b-c9284a7cf67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN(input_shape=1, hidden_dim=64, output_dim=30)\n",
    "\n",
    "EPOCHS = 60\n",
    "LEARNING_RATE = .02\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(cnn.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c9fa1-abd6-4b7b-be71-f5544efa3488",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20a434de-1538-4f47-a713-062a6f1a4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# Set number of epochs\n",
    "\n",
    "\n",
    "# Put data to target device\n",
    "train_X, train_Y = train_X.to(device), train_Y.to(device)\n",
    "val_X, val_Y = val_X.to(device), val_Y.to(device)\n",
    "cnn = cnn.to(device)\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_Y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(val_X, val_Y)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c638940-85af-4602-bf14-a032bf45ff8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 96, 96]) torch.Size([32, 30])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_dataloader:\n",
    "    print(X_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86da1397-2b7e-4777-b40b-e40dd6a5db7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 96, 96]) torch.Size([32, 30])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in test_dataloader:\n",
    "    print(X_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12ad2841-864e-486b-8311-fd2221b83b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch input:  torch.Size([32, 1, 96, 96])\n",
      "batch idx:  0\n",
      "batch label:  torch.Size([32, 30])\n",
      "---------- test dataloader -------\n",
      "0 torch.Size([32, 1, 96, 96])\n",
      "0 torch.Size([32, 30])\n"
     ]
    }
   ],
   "source": [
    "for idx,batch in enumerate(train_dataloader):\n",
    "    print(\"batch input: \", batch[0].size())\n",
    "    print(\"batch idx: \",  idx)\n",
    "    print(\"batch label: \" , batch[1].shape)\n",
    "    break\n",
    "\n",
    "print(\"---------- test dataloader -------\")\n",
    "for idx, (data,target) in enumerate(test_dataloader):\n",
    "    print(idx, data.shape)\n",
    "    print(idx, target.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15978b1-0307-45ff-8296-6a29bc257be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b4df8-53f1-4e33-85b9-1368b7fad442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77e29cc1-0e0b-429c-9e36-39a2a0d20694",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnn(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cb2792f1-948c-4486-84b5-991143b6bb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44ffb220-7fc5-40cb-a852-9129cf552503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2982, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(preds, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df5c82-ddd7-4bfa-a3e9-7a8d54cf9bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c30e184d-6e0e-4467-9314-f7d4cb56d895",
   "metadata": {},
   "source": [
    "## Training Loop (No gradient accumilation, see below for loop that's used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a89d1e-1476-4df9-91ba-2735db5ffdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7200e0fe-00c4-4379-94e0-1f6a2d7fe0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.00489 | Test Loss: 0.00172\n",
      "Epoch: 10 | Loss: 0.00196 | Test Loss: 0.00089\n",
      "Epoch: 20 | Loss: 0.00095 | Test Loss: 0.00078\n",
      "Epoch: 30 | Loss: 0.00376 | Test Loss: 0.00095\n",
      "Epoch: 40 | Loss: 0.00069 | Test Loss: 0.00025\n",
      "Epoch: 50 | Loss: 0.00053 | Test Loss: 0.00030\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    ### Training mode \n",
    "    cnn.train()\n",
    "\n",
    "    \n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        # 1. Forward pass (model outputs raw logits)\n",
    "        y_logits = cnn(X_batch)\n",
    "        \n",
    "        # 2. Calculate loss/accuracy\n",
    "        loss = loss_fn(y_logits, y_batch)\n",
    "        \n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Loss backwards\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    cnn.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_batch, y_batch in test_dataloader:\n",
    "            test_logits = cnn(X_batch)\n",
    "            test_loss = loss_fn(test_logits, y_batch)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Test Loss: {test_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be75b326-eb05-461d-b5ad-5906c2fac67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7f0496d-fca8-4ff9-9069-ae28287bdaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "07b1fdea-4d82-481f-a9be-33e1b85861c4",
   "metadata": {},
   "source": [
    "## Viewing a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548567ec-0f5a-4438-bb7d-57032d1822f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6131d851-04e5-4e85-b9d0-b0bd2d741ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342bf04-c9a2-4de6-b474-23b805e17937",
   "metadata": {},
   "source": [
    "## **THIS** error is why we use gradient accumilation, see next notebook (2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70099a6d-5d42-4676-8057-ddc661cf171a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.10 GiB (GPU 0; 15.74 GiB total capacity; 3.51 GiB already allocated; 1.17 GiB free; 3.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_X\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 10\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     11\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmax_pool2d(x, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, stride\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m     12\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv2(x))\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.10 GiB (GPU 0; 15.74 GiB total capacity; 3.51 GiB already allocated; 1.17 GiB free; 3.61 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "preds = cnn(val_X.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89d438-f832-4f00-8976-727bfcf76b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(preds.to(device), val_Y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd608735-e679-40ae-a53c-0296178e217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X.shape, preds.shape, val_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2aaa0-588f-4670-9325-8e910dd0b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba3416-86f1-45da-965d-de0db943b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X[1].shape, val_X[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f99dcf-b808-481e-85e3-1a58f7a06f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49344a7-2b32-4a4b-9662-f816ad0bdf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pred(X, preds, actual, index, point):\n",
    "    plt.imshow(X[index][0],cmap='gray')\n",
    "\n",
    "    plt.scatter(96* preds[index][point],96* preds[index][point + 1] ,c='r', marker='s', s=60, alpha=.5)\n",
    "    plt.scatter(96*actual[index][point],96* actual[index][point+1],c='g', marker='s', s=60, alpha=.5)\n",
    "\n",
    "    plt.legend(['predicted','actual'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ff6cd-4040-4e18-b81a-cc8cdb6e0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pred(val_X.to(\"cpu\"), preds.to(\"cpu\").detach().numpy(), val_Y.to(\"cpu\").detach().numpy(), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8ca82-1da8-4bae-adf8-61e2898f87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][0], preds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f924af9-d7ea-4378-8faa-452d28affd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Y[0][0], val_Y[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d8ab2-8430-4e89-a193-4fbfbb861075",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432aac6-20be-4360-aa43-ac1c9e1f6dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37776afd-9615-45e4-a3c9-4a6fb0ed6778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dece4a-be6c-4a91-b616-982504036173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d872651-4468-4966-9b2a-c15581494473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e742102-bf87-4352-9b8b-2a1466b3166d",
   "metadata": {},
   "source": [
    "## RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3aee4dc-5e71-4f16-914c-3e5ffdcdd0c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25a4df6-1c87-459a-816d-240a6a134920",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58b4cb5-b95d-4024-8dd1-9568c9653604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491509ee-7b38-4890-a585-3c104d51e1fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d2aa0c-e4fa-4da3-9819-647c345ec922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184b2c44-972b-422b-83ea-bdd78c620b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751707e-c698-4f54-b21c-445672de54ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bec1a0-8501-40db-920a-0a145f77f875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bcc21-8840-4685-aaf6-b17d789cda10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263c757-030a-41f9-8d58-682a6dd65ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815950f4-828a-4247-8f03-f12751337bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bb1d3-d1f0-451e-843e-7d7e4673dc24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1459a1-08b3-44ab-aa1a-951f5ab30cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36161f2d-0ab6-4a3b-b770-f55a6d6c0cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601218ec-2e94-4b68-be52-2b464f336557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7fc5d-43cc-4d2c-a7cc-b60d0aa7aacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676b16a-7420-4f93-8287-60ff22ad3706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1f495-5ae6-4505-a0de-0e366de370ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583eb203-3bcb-4408-8d9f-261845ea2591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
