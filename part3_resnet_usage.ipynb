{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19e84917-a74a-4d68-b738-20f8da9e8030",
   "metadata": {},
   "source": [
    "## Imports and Grab Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cea7897-6033-4325-a80d-21351e42ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.notebook_2_utils import * \n",
    "import utils.notebook_2_utils as utils\n",
    "\n",
    "training_df = pd.read_csv(\"data/training.csv\").iloc[:100]\n",
    "lookup_df = pd.read_csv(\"data/IdLookupTable.csv\")\n",
    "training_df.fillna(method = 'ffill',inplace = True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817a28ab-2502-485d-9db9-bb0ee01f348d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f050b1-6529-409a-9183-1845badd99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, val_X, val_Y = create_train_test_sets_nchw(training_df, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7629da-e48d-40d3-95eb-718337d2c576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e997724-0722-48c5-a13a-607178603462",
   "metadata": {},
   "source": [
    "## ResNet Model\n",
    "* Input shape:  64, 1, 96, 96 (nchw)\n",
    "* Output shape: 64, 30 (nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7ebfb08-d143-42bc-ba71-5c1383f60e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d371b-b988-4055-bdc4-86c844901904",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "492ce700-b41f-4c44-a5a7-b55916731ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f3bbc9ee78f465aa842059c312dce9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7ff48-ed7a-4ad3-8340-1d518917bdd4",
   "metadata": {},
   "source": [
    "## Control Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed53bd1-43f8-4d82-9d9b-c9284a7cf67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 40\n",
    "LEARNING_RATE = .02\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bdf9af-ef28-4fa0-a4c3-871acc3de536",
   "metadata": {},
   "source": [
    "## Replace first and Last layers\n",
    "* my input shape [32, 1, 96, 96] (NCHW) channels first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51ea5f3b-245e-4967-9eb9-a128b6b6b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# replace last layer\n",
    "resnet.fc = nn.Linear(512, 30) # 30 is the number of keypoints we want to predict\n",
    "\n",
    "# move to GPU\n",
    "resnet = resnet.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c9fa1-abd6-4b7b-be71-f5544efa3488",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20a434de-1538-4f47-a713-062a6f1a4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# Put data to target device\n",
    "train_X, train_Y = train_X.to(device), train_Y.to(device)\n",
    "val_X, val_Y = val_X.to(device), val_Y.to(device)\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_Y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(val_X, val_Y)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15978b1-0307-45ff-8296-6a29bc257be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b4df8-53f1-4e33-85b9-1368b7fad442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f914716-9bae-4bad-a828-6812b1ab8476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 96, 96]) torch.Size([32, 30])\n",
      "torch.Size([32, 1, 96, 96]) torch.Size([32, 30])\n",
      "torch.Size([16, 1, 96, 96]) torch.Size([16, 30])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_dataloader:\n",
    "    print(X_batch.shape, y_batch.shape)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77e29cc1-0e0b-429c-9e36-39a2a0d20694",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [64, 3, 7, 7], expected input[16, 1, 96, 96] to have 3 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [64, 3, 7, 7], expected input[16, 1, 96, 96] to have 3 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "preds = resnet(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2792f1-948c-4486-84b5-991143b6bb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ffb220-7fc5-40cb-a852-9129cf552503",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(preds, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df5c82-ddd7-4bfa-a3e9-7a8d54cf9bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c30e184d-6e0e-4467-9314-f7d4cb56d895",
   "metadata": {},
   "source": [
    "## Training Loop (No gradient accumilation, see below for loop that's used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a89d1e-1476-4df9-91ba-2735db5ffdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200e0fe-00c4-4379-94e0-1f6a2d7fe0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    ### Training mode \n",
    "    cnn.train()\n",
    "\n",
    "    \n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        # 1. Forward pass (model outputs raw logits)\n",
    "        y_logits = cnn(X_batch)\n",
    "        \n",
    "        # 2. Calculate loss/accuracy\n",
    "        loss = loss_fn(y_logits, y_batch)\n",
    "        \n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Loss backwards\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    cnn.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_batch, y_batch in test_dataloader:\n",
    "            test_logits = cnn(X_batch)\n",
    "            test_loss = loss_fn(test_logits, y_batch)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Test Loss: {test_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be75b326-eb05-461d-b5ad-5906c2fac67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70099a6d-5d42-4676-8057-ddc661cf171a",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = cnn(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c616b45-55dd-4035-b2fa-426bb1b0aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6c4d4-60fa-4678-a5ef-09a2eb23584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89d438-f832-4f00-8976-727bfcf76b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(preds.to(device), val_Y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd608735-e679-40ae-a53c-0296178e217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X.shape, preds.shape, val_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2aaa0-588f-4670-9325-8e910dd0b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba3416-86f1-45da-965d-de0db943b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X[1].shape, val_X[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f99dcf-b808-481e-85e3-1a58f7a06f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49344a7-2b32-4a4b-9662-f816ad0bdf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pred(X, preds, actual, index, point):\n",
    "    plt.imshow(X[index][0],cmap='gray')\n",
    "\n",
    "    plt.scatter(96* preds[index][point],96* preds[index][point + 1] ,c='r', marker='s', s=60, alpha=.5)\n",
    "    plt.scatter(96*actual[index][point],96* actual[index][point+1],c='g', marker='s', s=60, alpha=.5)\n",
    "\n",
    "    plt.legend(['predicted','actual'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ff6cd-4040-4e18-b81a-cc8cdb6e0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pred(val_X.to(\"cpu\"), preds.to(\"cpu\").detach().numpy(), val_Y.to(\"cpu\").detach().numpy(), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8ca82-1da8-4bae-adf8-61e2898f87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][0], preds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f924af9-d7ea-4378-8faa-452d28affd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Y[0][0], val_Y[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d8ab2-8430-4e89-a193-4fbfbb861075",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432aac6-20be-4360-aa43-ac1c9e1f6dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37776afd-9615-45e4-a3c9-4a6fb0ed6778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dece4a-be6c-4a91-b616-982504036173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d872651-4468-4966-9b2a-c15581494473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751707e-c698-4f54-b21c-445672de54ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bec1a0-8501-40db-920a-0a145f77f875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bcc21-8840-4685-aaf6-b17d789cda10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263c757-030a-41f9-8d58-682a6dd65ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815950f4-828a-4247-8f03-f12751337bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bb1d3-d1f0-451e-843e-7d7e4673dc24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1459a1-08b3-44ab-aa1a-951f5ab30cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36161f2d-0ab6-4a3b-b770-f55a6d6c0cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601218ec-2e94-4b68-be52-2b464f336557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7fc5d-43cc-4d2c-a7cc-b60d0aa7aacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676b16a-7420-4f93-8287-60ff22ad3706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1f495-5ae6-4505-a0de-0e366de370ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583eb203-3bcb-4408-8d9f-261845ea2591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
