{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5222725f-b26e-444d-bdbe-04ff0c4d43ea",
   "metadata": {},
   "source": [
    "## Notebook 4: find ideal LR for Resnet model, and add dropout (find optimal dropout probability)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e84917-a74a-4d68-b738-20f8da9e8030",
   "metadata": {},
   "source": [
    "## Imports and Grab Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cea7897-6033-4325-a80d-21351e42ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils.notebook_2_utils import * \n",
    "import utils.notebook_2_utils as utils\n",
    "\n",
    "training_df = pd.read_csv(\"data/training.csv\")\n",
    "lookup_df = pd.read_csv(\"data/IdLookupTable.csv\")\n",
    "training_df.fillna(method = 'ffill',inplace = True)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49a84918-bace-4b7c-bd64-b1ef774ede0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7049"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(training_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "817a28ab-2502-485d-9db9-bb0ee01f348d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "211470"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "7049*30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f050b1-6529-409a-9183-1845badd99e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_Y, val_X, val_Y = create_train_test_sets_nchw(training_df, normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7629da-e48d-40d3-95eb-718337d2c576",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e997724-0722-48c5-a13a-607178603462",
   "metadata": {},
   "source": [
    "## ResNet Model\n",
    "* Input shape:  64, 1, 96, 96 (nchw)\n",
    "* Output shape: 64, 30 (nc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7ebfb08-d143-42bc-ba71-5c1383f60e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087d371b-b988-4055-bdc4-86c844901904",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "492ce700-b41f-4c44-a5a7-b55916731ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d095a3-a011-42d2-9bf5-be616b0d65af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ee7ff48-ed7a-4ad3-8340-1d518917bdd4",
   "metadata": {},
   "source": [
    "## Control Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bed53bd1-43f8-4d82-9d9b-c9284a7cf67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 60\n",
    "LEARNING_RATE = .002\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(resnet.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d12fdec-8250-4676-9ac3-60e6cf46c64e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8b7b6d-4b05-45d9-8052-8a937530e502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f4bdf9af-ef28-4fa0-a4c3-871acc3de536",
   "metadata": {},
   "source": [
    "## Replace first and Last layers\n",
    "* my input shape [32, 1, 96, 96] (NCHW) channels first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51ea5f3b-245e-4967-9eb9-a128b6b6b0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all layers\n",
    "# for param in resnet.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# replace last layer\n",
    "resnet.fc = nn.Linear(512, 30) # 30 is the number of keypoints we want to predict\n",
    "\n",
    "# relpace the first layer\n",
    "resnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "\n",
    "# move to GPU\n",
    "resnet = resnet.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52bafc39-5e45-447c-893b-348df6f04c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "406e8004-8369-49f3-9c48-7b9028a5a1c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet.conv1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339c9fa1-abd6-4b7b-be71-f5544efa3488",
   "metadata": {},
   "source": [
    "### DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "20a434de-1538-4f47-a713-062a6f1a4229",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "# Put data to target device\n",
    "train_X, train_Y = train_X.to(device), train_Y.to(device)\n",
    "val_X, val_Y = val_X.to(device), val_Y.to(device)\n",
    "\n",
    "train_dataset = TensorDataset(train_X, train_Y)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(val_X, val_Y)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d35b6f6-ac9f-4cda-b4e3-43024afc9eea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dcf102d1-6951-42b9-b079-02bafd0a7c40",
   "metadata": {},
   "source": [
    "## Find Optimal LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0a2a942-b54f-4ba3-a2ad-99b6c05d95fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_lr = 10\n",
    "init_lr = 1e-10\n",
    "num_iters = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8280e04d-7199-4992-9f00-12621270a0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_lr(model, train_loader, criterion, optimizer, init_lr=1e-8, final_lr=10, num_iters=100):\n",
    "    \"\"\"\n",
    "    Finds the optimal learning rate for the model by gradually increasing the learning rate and plotting the loss.\n",
    "    Args:\n",
    "    - model (torch.nn.Module): the PyTorch model to train\n",
    "    - train_loader (torch.utils.data.DataLoader): the training data loader\n",
    "    - criterion (torch.nn.Module): the loss function\n",
    "    - optimizer (torch.optim.Optimizer): the optimizer\n",
    "    - init_lr (float): the initial learning rate\n",
    "    - final_lr (float): the final learning rate\n",
    "    - num_iters (int): the number of iterations to run\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    optimizer.param_groups[0]['lr'] = init_lr\n",
    "    \n",
    "    init, final = math.log(init_lr, 10), math.log(final_lr, 10)\n",
    "\n",
    "    \n",
    "    lr_steps = np.logspace(init, final, num=num_iters+1)\n",
    "    lr = init_lr\n",
    "    losses = []\n",
    "    lrs = []\n",
    "    lrs_dx = []\n",
    "    \n",
    "    for i, (inputs, targets) in enumerate(train_loader):\n",
    "        if i >= num_iters:\n",
    "            break\n",
    "        \n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "        inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        lrs.append(lr)\n",
    "        if i != 0: \n",
    "            lrs_dx.append(loss.item() - losses[i-1]) \n",
    "        lr = lr_steps[i]\n",
    "    \n",
    "    # plot the learning rate vs. loss\n",
    "    plt.plot(lrs, losses)\n",
    "    plt.xscale('log')\n",
    "    plt.xlabel('Learning Rate')\n",
    "    plt.ylabel('Loss')\n",
    "    \n",
    "    max = np.argmin(lrs_dx)\n",
    "    min = np.argmin(losses)\n",
    "    \n",
    "    text = \"highest delta: \" + str(lrs[max])[:7] + \" lowest loss: \" + str(lrs[min])[:7]\n",
    "    plt.title(text)\n",
    "    \n",
    "    plt.scatter(lrs[min], losses[min], c=\"r\")\n",
    "    plt.scatter(lrs[max], losses[max], c=\"g\")\n",
    "    \n",
    "    plt.show()\n",
    "    return losses, lrs, lrs_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e996934c-eb66-4baa-9364-5f40a17551b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0cfe9-6b51-4ff5-afe6-dc1fd0977a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc6822b2-eef2-417a-9d08-286953fb3990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses, lrs, lrs_dx = find_lr(resnet, train_dataloader, loss_fn, optimizer, final_lr=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e3dca2-4d65-41c3-8143-55a2ce8cc1c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86b4df8-53f1-4e33-85b9-1368b7fad442",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f914716-9bae-4bad-a828-6812b1ab8476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 96, 96]) torch.Size([32, 30])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_dataloader:\n",
    "    print(X_batch.shape, y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "77e29cc1-0e0b-429c-9e36-39a2a0d20694",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = resnet.to(device)\n",
    "\n",
    "preds = resnet(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bb70ef42-869f-46b9-9f21-abebd971f1df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dff0a7d-acc4-4e39-99d1-e6a444bb91c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8526, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = loss_fn(preds, y_batch)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e66f610e-0c08-4716-b3f2-9aff199178ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch norm 1: \n",
      "True\n",
      "True\n",
      "CONV1: \n",
      "True\n",
      "fc: \n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Checking to make sure the right layers are frozen\n",
    "\n",
    "print(\"batch norm 1: \")\n",
    "for param in resnet.bn1.parameters():\n",
    "    print(param.requires_grad)\n",
    "    \n",
    "print(\"CONV1: \")\n",
    "for param in resnet.conv1.parameters():\n",
    "    print(param.requires_grad)\n",
    "\n",
    "print(\"fc: \")\n",
    "for param in resnet.fc.parameters():\n",
    "    print(param.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4bed8a-bd9c-4b35-b038-4ab014faf266",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb2792f1-948c-4486-84b5-991143b6bb64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 30])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac11fd-057e-4569-a7b6-6e1189b370a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "44ffb220-7fc5-40cb-a852-9129cf552503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8526, device='cuda:0', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn(preds, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6df5c82-ddd7-4bfa-a3e9-7a8d54cf9bfa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c30e184d-6e0e-4467-9314-f7d4cb56d895",
   "metadata": {},
   "source": [
    "## Training Loop "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a89d1e-1476-4df9-91ba-2735db5ffdb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7200e0fe-00c4-4379-94e0-1f6a2d7fe0c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 | Loss: 0.70826 | Test Loss: 0.58285\n",
      "Epoch: 10 | Loss: 0.13220 | Test Loss: 0.09554\n",
      "Epoch: 20 | Loss: 0.19193 | Test Loss: 0.06232\n",
      "Epoch: 30 | Loss: 0.02310 | Test Loss: 0.01310\n",
      "Epoch: 40 | Loss: 0.24047 | Test Loss: 0.00743\n",
      "Epoch: 50 | Loss: 0.01440 | Test Loss: 0.00302\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCHS):\n",
    "    ### Training mode \n",
    "    resnet.train()\n",
    "\n",
    "    \n",
    "    for X_batch, y_batch in train_dataloader:\n",
    "        # 1. Forward pass (model outputs raw logits)\n",
    "        y_logits = resnet(X_batch)\n",
    "        \n",
    "        # 2. Calculate loss/accuracy\n",
    "        loss = loss_fn(y_logits, y_batch)\n",
    "        \n",
    "        # 3. Optimizer zero grad\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # 4. Loss backwards\n",
    "        loss.backward()\n",
    "        \n",
    "        # 5. Optimizer step\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    resnet.eval()\n",
    "    with torch.inference_mode():\n",
    "        for X_batch, y_batch in test_dataloader:\n",
    "            test_logits = resnet(X_batch)\n",
    "            test_loss = loss_fn(test_logits, y_batch)\n",
    "\n",
    "    # Print out what's happening\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch} | Loss: {loss:.5f} | Test Loss: {test_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be75b326-eb05-461d-b5ad-5906c2fac67b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "70099a6d-5d42-4676-8057-ddc661cf171a",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 794.00 MiB (GPU 0; 15.90 GiB total capacity; 5.66 GiB already allocated; 4.50 MiB free; 5.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [35]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mresnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval_X\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[1;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py:457\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py:453\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    450\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    451\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    452\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 794.00 MiB (GPU 0; 15.90 GiB total capacity; 5.66 GiB already allocated; 4.50 MiB free; 5.73 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "preds = resnet(val_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c616b45-55dd-4035-b2fa-426bb1b0aa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd6c4d4-60fa-4678-a5ef-09a2eb23584c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc89d438-f832-4f00-8976-727bfcf76b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(preds.to(device), val_Y.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd608735-e679-40ae-a53c-0296178e217c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X.shape, preds.shape, val_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa2aaa0-588f-4670-9325-8e910dd0b58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bba3416-86f1-45da-965d-de0db943b39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_X[1].shape, val_X[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f99dcf-b808-481e-85e3-1a58f7a06f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49344a7-2b32-4a4b-9662-f816ad0bdf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_pred(X, preds, actual, index, point):\n",
    "    plt.imshow(X[index][0],cmap='gray')\n",
    "\n",
    "    plt.scatter(96* preds[index][point],96* preds[index][point + 1] ,c='r', marker='s', s=60, alpha=.5)\n",
    "    plt.scatter(96*actual[index][point],96* actual[index][point+1],c='g', marker='s', s=60, alpha=.5)\n",
    "\n",
    "    plt.legend(['predicted','actual'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ff6cd-4040-4e18-b81a-cc8cdb6e0823",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_pred(val_X.to(\"cpu\"), preds.to(\"cpu\").detach().numpy(), val_Y.to(\"cpu\").detach().numpy(), 0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce8ca82-1da8-4bae-adf8-61e2898f87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[0][0], preds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f924af9-d7ea-4378-8faa-452d28affd5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.6736, device='cuda:0'), tensor(0.3915, device='cuda:0'))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_Y[0][0], val_Y[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9d8d8ab2-8430-4e89-a193-4fbfbb861075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1843, 0.1529, 0.1255,  ..., 0.2902, 0.2980, 0.3137],\n",
       "        [0.1725, 0.1529, 0.1333,  ..., 0.2863, 0.2941, 0.3059],\n",
       "        [0.1686, 0.1608, 0.1451,  ..., 0.2863, 0.2941, 0.2980],\n",
       "        ...,\n",
       "        [0.2902, 0.2902, 0.2902,  ..., 0.2314, 0.2353, 0.2392],\n",
       "        [0.2980, 0.2902, 0.2863,  ..., 0.2353, 0.2392, 0.2471],\n",
       "        [0.3059, 0.2941, 0.2824,  ..., 0.2431, 0.2431, 0.2471]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7432aac6-20be-4360-aa43-ac1c9e1f6dac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37776afd-9615-45e4-a3c9-4a6fb0ed6778",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dece4a-be6c-4a91-b616-982504036173",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d872651-4468-4966-9b2a-c15581494473",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a751707e-c698-4f54-b21c-445672de54ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bec1a0-8501-40db-920a-0a145f77f875",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bcc21-8840-4685-aaf6-b17d789cda10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263c757-030a-41f9-8d58-682a6dd65ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815950f4-828a-4247-8f03-f12751337bd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02bb1d3-d1f0-451e-843e-7d7e4673dc24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1459a1-08b3-44ab-aa1a-951f5ab30cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36161f2d-0ab6-4a3b-b770-f55a6d6c0cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601218ec-2e94-4b68-be52-2b464f336557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d7fc5d-43cc-4d2c-a7cc-b60d0aa7aacd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8676b16a-7420-4f93-8287-60ff22ad3706",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b1f495-5ae6-4505-a0de-0e366de370ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583eb203-3bcb-4408-8d9f-261845ea2591",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
